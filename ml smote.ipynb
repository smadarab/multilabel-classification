{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Importing required Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_sample=1000):\n",
    "    ''' \n",
    "    Create a unevenly distributed sample data set multilabel  \n",
    "    classification using make_classification function\n",
    "    \n",
    "    args\n",
    "    nsample: int, Number of sample to be created\n",
    "    \n",
    "    return\n",
    "    X: pandas.DataFrame, feature vector dataframe with 10 features \n",
    "    y: pandas.DataFrame, target vector dataframe with 5 labels\n",
    "    '''\n",
    "    X, y = make_classification(n_classes=5, class_sep=2, \n",
    "                           weights=[0.1,0.025, 0.205, 0.008, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=10, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "    y = pd.get_dummies(y, prefix='class')\n",
    "    return pd.DataFrame(X), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tail_label(df):\n",
    "    \"\"\"\n",
    "    Give tail label colums of the given target dataframe\n",
    "    \n",
    "    args\n",
    "    df: pandas.DataFrame, target label df whose tail label has to identified\n",
    "    \n",
    "    return\n",
    "    tail_label: list, a list containing column name of all the tail label\n",
    "    1.takes value counts of first category in all columns and forms a list with those values\n",
    "    2.devided the max of list with the each values of list \n",
    "    3.calucalte average\n",
    "    4.iterate thorogh the each value of list and if that value is above avergae the append that column to the fnal list  \n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    print(\"columns\",columns)\n",
    "    n = len(columns)\n",
    "    irpl = np.zeros(n)\n",
    "    print(irpl)\n",
    "    for column in range(n):\n",
    "        irpl[column] = df[columns[column]].value_counts()[1]\n",
    "    print(\"after iteration\",(max(irpl)/irpl),irpl,np.average(irpl))    \n",
    "    irpl = max(irpl)/irpl\n",
    "    \n",
    "    mir = np.average(irpl)\n",
    "    print(\"mir\",mir)\n",
    "    tail_label = []\n",
    "    for i in range(n):\n",
    "        if irpl[i] > mir:\n",
    "            print(\"columns\",columns[i],irpl[i])\n",
    "            tail_label.append(columns[i])\n",
    "    print(tail_label)        \n",
    "    return tail_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(df):\n",
    "  \"\"\"\n",
    "  give the index of all tail_label rows\n",
    "  args\n",
    "  df: pandas.DataFrame, target label df from which index for tail label has to identified\n",
    "    \n",
    "  return\n",
    "  index: list, a list containing index number of all the tail label\n",
    "  retursn all the rows index of minroty elements\n",
    "  \"\"\"\n",
    "  tail_labels = get_tail_label(df)\n",
    "  index = set()\n",
    "  for tail_label in tail_labels:\n",
    "    sub_index = set(df[df[tail_label]==1].index)\n",
    "    index = index.union(sub_index)\n",
    "  return list(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minority_instace(X, y):\n",
    "    \"\"\"\n",
    "    Give minority dataframe containing all the tail labels\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, the feature vector dataframe\n",
    "    y: pandas.DataFrame, the target vector dataframe\n",
    "    \n",
    "    return\n",
    "    X_sub: pandas.DataFrame, the feature vector minority dataframe\n",
    "    y_sub: pandas.DataFrame, the target vector minority dataframe\n",
    "    \"\"\"\n",
    "    index = get_index(y)\n",
    "    \n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(X):\n",
    "    \"\"\"\n",
    "    Give index of 5 nearest neighbor of all the instance\n",
    "    \n",
    "    args\n",
    "    X: np.array, array whose nearest neighbor has to find\n",
    "    \n",
    "    return\n",
    "    indices: list of list, index of 5 NN of each element in X\n",
    "    \"\"\"\n",
    "    nbs=NearestNeighbors(n_neighbors=5,metric='euclidean',algorithm='kd_tree').fit(X)\n",
    "    euclidean,indices= nbs.kneighbors(X)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLSMOTE(X,y, n_sample):\n",
    "    \"\"\"\n",
    "    Give the augmented data using MLSMOTE algorithm\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, input vector DataFrame\n",
    "    y: pandas.DataFrame, feature vector dataframe\n",
    "    n_sample: int, number of newly generated sample\n",
    "    \n",
    "    return\n",
    "    new_X: pandas.DataFrame, augmented feature vector data\n",
    "    target: pandas.DataFrame, augmented target vector data\n",
    "    \"\"\"\n",
    "    indices2 = nearest_neighbour(X)\n",
    "    print(indices2)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_sample, X.shape[1]))\n",
    "    target = np.zeros((n_sample, y.shape[1]))\n",
    "    for i in range(n_sample):\n",
    "        reference = random.randint(0,n-1)\n",
    "        neighbour = random.choice(indices2[reference,1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val>2 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbour,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    new_X = pd.concat([X, new_X], axis=0)\n",
    "    target = pd.concat([y, target], axis=0)\n",
    "    return new_X, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \"\"\"\n",
    "    main function to use the MLSMOTE\n",
    "    \"\"\"\n",
    "    X, y = create_dataset()                     #Creating a Dataframe\n",
    "      #Applying MLSMOTE to augment the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    900\n",
       "1    100\n",
       "Name: class_0, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    975\n",
       "1     25\n",
       "Name: class_1, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12,\n",
       " 54,\n",
       " 58,\n",
       " 148,\n",
       " 188,\n",
       " 205,\n",
       " 231,\n",
       " 267,\n",
       " 313,\n",
       " 326,\n",
       " 346,\n",
       " 410,\n",
       " 420,\n",
       " 433,\n",
       " 529,\n",
       " 537,\n",
       " 562,\n",
       " 621,\n",
       " 626,\n",
       " 633,\n",
       " 668,\n",
       " 678,\n",
       " 695,\n",
       " 711,\n",
       " 737,\n",
       " 744,\n",
       " 860,\n",
       " 884,\n",
       " 928,\n",
       " 934,\n",
       " 937,\n",
       " 948,\n",
       " 996}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y[y['class_1']==1].index).union(set(y[y['class_3']==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    795\n",
       "1    205\n",
       "Name: class_2, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    992\n",
       "1      8\n",
       "Name: class_3, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    662\n",
       "0    338\n",
       "Name: class_4, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns Index(['class_0', 'class_1', 'class_2', 'class_3', 'class_4'], dtype='object')\n",
      "[0. 0. 0. 0. 0.]\n",
      "after iteration [ 6.62       26.48        3.22926829 82.75        1.        ] [100.  25. 205.   8. 662.] 200.0\n",
      "mir 24.015853658536585\n",
      "columns class_1 26.48\n",
      "columns class_3 82.75\n",
      "['class_1', 'class_3']\n"
     ]
    }
   ],
   "source": [
    " X_sub, y_sub = get_minority_instace(X, y)   #Getting minority instance of that datframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "0     8\n",
       "Name: class_1, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub['class_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 13  6 12  8]\n",
      " [ 1 28 13 29  8]\n",
      " [ 2 27 26 10 24]\n",
      " [ 3 13 29 21 25]\n",
      " [ 4 19 31 18 25]\n",
      " [ 5 24 30 10  2]\n",
      " [ 6  8  0 13 20]\n",
      " [ 7  8  6 13 18]\n",
      " [ 8  6 13  7  0]\n",
      " [ 9 28  1 31 16]\n",
      " [10 26 24 20 27]\n",
      " [11 21 32 13  6]\n",
      " [12 13  0 18 20]\n",
      " [13 12 32 18  0]\n",
      " [14 13 25 20  0]\n",
      " [15  2 27 10 26]\n",
      " [16 12  9 13  1]\n",
      " [17 31 25 13 20]\n",
      " [18 13 25 28 32]\n",
      " [19  4 25 18 17]\n",
      " [20  0 17  6 12]\n",
      " [21 11 13 32  3]\n",
      " [22 18 13 28 31]\n",
      " [23 12  1 31 13]\n",
      " [24  5 10 30 14]\n",
      " [25 17 13 18 32]\n",
      " [26 10  2 27 30]\n",
      " [27  2 10 26 24]\n",
      " [28 32  1 18 13]\n",
      " [29  1  8 28 25]\n",
      " [30 24 10  5 26]\n",
      " [31 17 25 13 12]\n",
      " [32 13 28 25 18]]\n"
     ]
    }
   ],
   "source": [
    "X_res,y_res =MLSMOTE(X_sub, y_sub, 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaea93298ad34b4164b12094db0c35890f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
